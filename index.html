<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>SSL-HWE: Semi-supervised Learning-based Hierarchical Waypoint Extraction for Imitation Learning in Robotic Manipulation</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">SSL-HWE: Semi-supervised Learning-based Hierarchical Waypoint Extraction for Imitation Learning in Robotic Manipulation</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="FIRST AUTHOR PERSONAL LINK" target="_blank">Xinzi Liu</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="SECOND AUTHOR PERSONAL LINK" target="_blank">Xinyu Zhai</a><sup>1</sup>,</span>
                  <span class="author-block">
                    <a href="THIRD AUTHOR PERSONAL LINK" target="_blank">Junwei Liu</a><sup>1</sup>,</span>
                  </span>
                  <span class="author-block">
                    <a href="http://www.wzhanglab.site/" target="_blank">Wei Zhang</a><sup>1,2</sup></span>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Southern University of Science and Technology</span>
                    <br>
                    <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Corresponding Author</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <!-- <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span> -->

                <!-- ArXiv abstract Link -->
                <!-- <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span> -->
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/TOP_video_o.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered is-6">
        TODO First video.
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column">
        <h2 class="title is-3">Introduction</h2>
        <div class="content has-text-justified">
          <p>
            <style>
              .indented {
                text-indent: 2em;
              }
            </style>
            </head>
            <body>
            <p class="indented">
              In recent years, imitation learning based on behavioral
              cloning has become an efficient method in automated vehicle
              control as well as robot manipulation. Imitation
              learning learns strategies from expert demonstrations by
              observing and imitating the behavior of human experts to
              learn to perform a specific task; more specifically, it directly
              converts the end-to-end mapping decision of observation to
              action into a supervised learning problem, effectively
              solving the problems of model dependence in model-based
              approaches and the difficulty of determining the reward
              function and the large exploration range in reinforcement
              learning algorithms.
            </p>
            <p class="indented">
              Imitation learning is still limited by the problem of com
              pounding errors, the accumulation of small errors
               in predicting actions that lead to errors in the distribution
               of evaluation data versus the distribution of training data.
               Most of the previous work on compounding errors consists
               of increasing the number of datasets and optimizing the
               model structure, but almost ignores just processing the
               datasets without additional new data. It is well known that
               the high success rate of imitation learning algorithms in a
               given task depends heavily on high-quality datasets. High
               quality in this context can be defined as fewer interfering
               trajectories and simpler and easier to understand execution
               strategies, e.g. if the experiment is to grasp a cup at a
               specified location, we would like the robotic arm to approach
               the cup faster and more directly and grasp it steadily, rather
               than zigzagging and colliding with the cup several times and
               then barely grasping it. Redundant trajectories do not have
               the effect of increasing the training data, but instead have
               the side effect of being intrusive and misleading; in other
               words, a high-quality dataset also implies a simpler and more
               learnable data distribution. Imitation learning datasets are
               precious and scarce, and requiring high-quality datasets only
               limits the utility of the model. We would like to accept the
               instability of dataset quality and improve the quality of the
               dataset through data processing to reduce the complexity of the dataset distribution and enhance learnability. In imitation
               learning, information about the current environment is often
               difficult to change, which requires modeling the known
               environment or obtaining more known information, but it
               has been demonstrated that ensuring consistency of actions
               in type situations can be effective in improving the stability
               of strategies by making appropriate modifications to the mod
              ifiable target sequences. Therefore, circumventing
               useless and redundant actions by directly acting on the action
               sequences in an appropriate way not only simplifies the data
               set distribution but also improves action consistency, which
               is a feasible solution to the above mentioned requirements.
            </p>
            <p class="indented">
              <strong>Imitation Learning.</strong>
            </p>

            <p class="indented">
              <strong>Model Structure.</strong>
              Imitation learning learns strategies
              through expert dataset, and its deployment effectiveness
              depends on the learning ability of the model and the quality
              of the expert example dataset. To combat compound errors,
              previous work has used new policy architectures such as
              the use of implicit representations or diffusion strategies 
              to improve the model's learning ability and adapt
              to complex data distributions. Since our approach does not
              require modifications to the model, it is compatible with
              these approaches.
            </p>
            <p class="indented">
              <strong>Dataset.</strong>
              In addition to this, modifications to the dataset
              can be made in two general directions, the first of which
              is to reduce unfamiliar states by increasing the amount and
              range of states in the dataset with the intention of covering
              all states as much as possible. Examples include increasing
              the data range by adding noise during data collection
              or using online datasets to improve deployment
              performance. The second is by reducing the decision scope,
              i.e., modifying the dataset and simplifying it by removing
              redundant data. Some people use heuristics based on end
             effector characteristics or robot speed, or reconstruction
              errors between waypoints and the original trajectory. 
              These approaches directly extract waypoints,
              which do not guarantee the success rate of reproducing the
              points after fetching them, or the waypoints may miss the
              real critical points that determine the success of the task
              due to the difference in the definition of the fetched points.
              Alternatively, paths can be divided into sparse vs. dense and
              proximity vs. interaction phases to modify the
              action, but how to differentiate between the different phases
              of the paths requires the introduction of a large number
              of human calibrations or complete knowledge of the task
              phases, which introduces additional work and limitations. We
              combine the advantages of the above multiple ideas to avoid
              the omission possibility of blind point taking and the large
              amount of human work.
            </p>
          </body>
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Method Overview -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <br>
      <h2 class="title is-4">Method Overview</h2>
        <div class="content">
          <p>
            <style>
              /* CSS样式 */
              .indented {
                text-indent: 2em; /* 首行缩进2em */
              }
            </style>
            </head>
            <body>
            
            <p class="indented">
              We propose a data processing method Semi-supervised
              Learning-based Hierarchical Waypoint Extraction (SSL-HWE) to en
             hance downstream imitation learning from human demon
             stration datasets. Our approach involves two main steps: (1)
              Key Interval Segmentation: We use semi-supervised learn
             ing on side-view image sequences to predict key intervals. (2)
              Hierarchical Waypoint Extraction: We formulate and solve
              optimization problems with interval-specific constraints to
              determine an efficient waypoint selection vector. This vector
              guides the adjustment of actions in the demonstration dataset,
              resulting in a refined dataset that reduces compounding
              errors in imitation learning.</p>
            </body>
           
          </p>
        </div>

       <div class="item", style="text-align: center;">
        <!-- Your image here -->
        <img src="static/images/scact.png" alt="MY ALT TEXT"/>
        <!-- <h2 class="subtitle has-text-centered">
          First image description.
        </h2> -->
      </div>
      

</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container"> -->
      <!-- Paper video. -->
      <!-- <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video"> -->
            <!-- Youtube embed code here -->
            <!-- <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-4">Evaluation Results</h2>
      <!-- <p>
        blablabla
      </p> -->
      <h3 class="title is-5">Task 1: Kitchen</h3>
        <div class="content">
          <p>
            <style>
              /* CSS样式 */
              .indented {
                text-indent: 2em; /* 首行缩进2em */
              }
            </style>
            </head>
            <body>
            
            <p class="indented">
              Place the pot on the induction cooker and add tomatoes and green peppers into the pot.</p>
            </body>
  
          </p>
        </div>
      <!-- <p>
        blablabla
      </p> -->
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/Task1/Kitchen_ssl-hwe.mp4"
            type="video/mp4">
          </video>
          <h3 class="subtitle has-text-centered", style="margin-top: 20px;">
            <b>SSL-HWE + ACT(ours)</b>
          </h3>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/Task1/Kitchen_awe.mp4"
            type="video/mp4">
          </video>
          <h3 class="subtitle has-text-centered", style="margin-top: 20px;">
            AWE + ACT
          </h3>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/Task1/Kitchen_act.mp4"
            type="video/mp4">
          </video>
          <h3 class="subtitle has-text-centered", style="margin-top: 20px;">
            ACT
          </h3>
        </div>
      </div>

      <br>
      <h3 class="title is-5">Task 2: Desk storage</h3>
        <div class="content">
          <p>
            <style>
              /* CSS样式 */
              .indented {
                text-indent: 2em; /* 首行缩进2em */
              }
            </style>
            </head>
            <body>
            
            <p class="indented">
              Use the robotic arm to pull the drawer open, 
              then place the tissues and the figurine in the drawer, and finally close the drawer.</p>
            </body>

          </p>
        </div>
      <!-- <p>
        blablabla
      </p> -->
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/Task2/hwe.mp4"
            type="video/mp4">
          </video>
          <h3 class="subtitle has-text-centered", style="margin-top: 20px;">
            <b>SSL-HWE + ACT(ours)</b>
          </h3>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/Task2/awe.mp4"
            type="video/mp4">
          </video>
          <h3 class="subtitle has-text-centered", style="margin-top: 20px;">
            AWE + ACT
          </h3>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/Task2/act.mp4"
            type="video/mp4">
          </video>
          <h3 class="subtitle has-text-centered", style="margin-top: 20px;">
            ACT
          </h3>
        </div>
      </div>

      <br>
      <h3 class="title is-5">Task 3: Desk clear</h3>
        <div class="content">
          <p>
            <style>
              /* CSS样式 */
              .indented {
                text-indent: 2em; /* 首行缩进2em */
              }
            </style>
            </head>
            <body>
            
            <p class="indented">

              First, use the robotic arm to pick up the broom and dustpan respectively, 
              then sweep the two clumps of garbage randomly distributed in the square area into the dustpan, 
              and then put the broom and dustpan back into place.</p>
            </body>

          </p>
        </div>
      <!-- <p>
        blablabla
      </p> -->
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/Task3/hwe.mp4"
            type="video/mp4">
          </video>
          <h3 class="subtitle has-text-centered", style="margin-top: 20px;">
            <b>SSL-HWE + ACT(ours)</b>
          </h3>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%">
            <!-- Your video file here -->
            <source src="static/videos/Task3/awe.mp4"
            type="video/mp4">
          </video>
          <h3 class="subtitle has-text-centered", style="margin-top: 20px;">
            AWE + ACT
          </h3>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\
            <!-- Your video file here -->
            <source src="static/videos/Task3/act.mp4"
            type="video/mp4">
          </video>
          <h3 class="subtitle has-text-centered", style="margin-top: 20px;">
            ACT
          </h3>
        </div>
      </div>



    </div>
  </div>
</section>
<!-- End video carousel -->






<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <!-- <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer> -->

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
